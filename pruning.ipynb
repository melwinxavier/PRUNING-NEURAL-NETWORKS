{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af20037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries required for this task\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as functional\n",
    "import torch.nn.utils.prune as prune \n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import  datasets\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import rankdata\n",
    "from collections import OrderedDict\n",
    "from numpy import linalg \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24e5ddf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# selection of device and dataset creation\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "train = datasets.MNIST('', train=True, download=True,transform=ToTensor())\n",
    "test = datasets.MNIST('', train=False, download=True,transform=ToTensor())\n",
    "\n",
    "batch_size = 7\n",
    "\n",
    "train_dataset = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = DataLoader(test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "888e586e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (fc1): Linear(in_features=784, out_features=1000, bias=False)\n",
      "  (fc2): Linear(in_features=1000, out_features=1000, bias=False)\n",
      "  (fc3): Linear(in_features=1000, out_features=500, bias=False)\n",
      "  (fc4): Linear(in_features=500, out_features=200, bias=False)\n",
      "  (fc5): Linear(in_features=200, out_features=10, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Neuralnet model impelementation using the provided task instruction\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 1000, bias=False)\n",
    "        self.fc2 = nn.Linear(1000, 1000, bias=False)\n",
    "        self.fc3 = nn.Linear(1000, 500, bias=False)\n",
    "        self.fc4 = nn.Linear(500, 200, bias=False)\n",
    "        self.fc5 = nn.Linear(200, 10, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = functional.relu(self.fc1(x))\n",
    "        x = functional.relu(self.fc2(x))\n",
    "        x = functional.relu(self.fc3(x))\n",
    "        x = functional.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return functional.log_softmax(x, dim=1)\n",
    "\n",
    "model = NeuralNet()\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f109aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring loss as crossentropy function and opmizer function as SGD\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83144111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function decleration\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X.view(-1,784))\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6572d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing function decleration\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X.view(-1,784))\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Result: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc8e0917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.303744  [    0/60000]\n",
      "loss: 2.304600  [  700/60000]\n",
      "loss: 2.302722  [ 1400/60000]\n",
      "loss: 2.302054  [ 2100/60000]\n",
      "loss: 2.300972  [ 2800/60000]\n",
      "loss: 2.299482  [ 3500/60000]\n",
      "loss: 2.303353  [ 4200/60000]\n",
      "loss: 2.303372  [ 4900/60000]\n",
      "loss: 2.301974  [ 5600/60000]\n",
      "loss: 2.302824  [ 6300/60000]\n",
      "loss: 2.302366  [ 7000/60000]\n",
      "loss: 2.299838  [ 7700/60000]\n",
      "loss: 2.304569  [ 8400/60000]\n",
      "loss: 2.300370  [ 9100/60000]\n",
      "loss: 2.300874  [ 9800/60000]\n",
      "loss: 2.298204  [10500/60000]\n",
      "loss: 2.305406  [11200/60000]\n",
      "loss: 2.300513  [11900/60000]\n",
      "loss: 2.300972  [12600/60000]\n",
      "loss: 2.292707  [13300/60000]\n",
      "loss: 2.301047  [14000/60000]\n",
      "loss: 2.297348  [14700/60000]\n",
      "loss: 2.297167  [15400/60000]\n",
      "loss: 2.297240  [16100/60000]\n",
      "loss: 2.300055  [16800/60000]\n",
      "loss: 2.299230  [17500/60000]\n",
      "loss: 2.300952  [18200/60000]\n",
      "loss: 2.296180  [18900/60000]\n",
      "loss: 2.296384  [19600/60000]\n",
      "loss: 2.297400  [20300/60000]\n",
      "loss: 2.298769  [21000/60000]\n",
      "loss: 2.293480  [21700/60000]\n",
      "loss: 2.292844  [22400/60000]\n",
      "loss: 2.296293  [23100/60000]\n",
      "loss: 2.297109  [23800/60000]\n",
      "loss: 2.299051  [24500/60000]\n",
      "loss: 2.299123  [25200/60000]\n",
      "loss: 2.294640  [25900/60000]\n",
      "loss: 2.290987  [26600/60000]\n",
      "loss: 2.299748  [27300/60000]\n",
      "loss: 2.298507  [28000/60000]\n",
      "loss: 2.292596  [28700/60000]\n",
      "loss: 2.299500  [29400/60000]\n",
      "loss: 2.288693  [30100/60000]\n",
      "loss: 2.293719  [30800/60000]\n",
      "loss: 2.300766  [31500/60000]\n",
      "loss: 2.291573  [32200/60000]\n",
      "loss: 2.293359  [32900/60000]\n",
      "loss: 2.292846  [33600/60000]\n",
      "loss: 2.294117  [34300/60000]\n",
      "loss: 2.293247  [35000/60000]\n",
      "loss: 2.292349  [35700/60000]\n",
      "loss: 2.293674  [36400/60000]\n",
      "loss: 2.292220  [37100/60000]\n",
      "loss: 2.296217  [37800/60000]\n",
      "loss: 2.288521  [38500/60000]\n",
      "loss: 2.298640  [39200/60000]\n",
      "loss: 2.284161  [39900/60000]\n",
      "loss: 2.290989  [40600/60000]\n",
      "loss: 2.290519  [41300/60000]\n",
      "loss: 2.277067  [42000/60000]\n",
      "loss: 2.278812  [42700/60000]\n",
      "loss: 2.293613  [43400/60000]\n",
      "loss: 2.285496  [44100/60000]\n",
      "loss: 2.284810  [44800/60000]\n",
      "loss: 2.296326  [45500/60000]\n",
      "loss: 2.292891  [46200/60000]\n",
      "loss: 2.292446  [46900/60000]\n",
      "loss: 2.292931  [47600/60000]\n",
      "loss: 2.270942  [48300/60000]\n",
      "loss: 2.279688  [49000/60000]\n",
      "loss: 2.290480  [49700/60000]\n",
      "loss: 2.278031  [50400/60000]\n",
      "loss: 2.283432  [51100/60000]\n",
      "loss: 2.280922  [51800/60000]\n",
      "loss: 2.270618  [52500/60000]\n",
      "loss: 2.271821  [53200/60000]\n",
      "loss: 2.293596  [53900/60000]\n",
      "loss: 2.293273  [54600/60000]\n",
      "loss: 2.258406  [55300/60000]\n",
      "loss: 2.291074  [56000/60000]\n",
      "loss: 2.284577  [56700/60000]\n",
      "loss: 2.287098  [57400/60000]\n",
      "loss: 2.292087  [58100/60000]\n",
      "loss: 2.267381  [58800/60000]\n",
      "loss: 2.274234  [59500/60000]\n",
      "Test Result: \n",
      " Accuracy: 34.7%, Avg loss: 2.273157 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.292818  [    0/60000]\n",
      "loss: 2.244885  [  700/60000]\n",
      "loss: 2.277192  [ 1400/60000]\n",
      "loss: 2.274119  [ 2100/60000]\n",
      "loss: 2.287216  [ 2800/60000]\n",
      "loss: 2.261685  [ 3500/60000]\n",
      "loss: 2.261315  [ 4200/60000]\n",
      "loss: 2.262973  [ 4900/60000]\n",
      "loss: 2.280383  [ 5600/60000]\n",
      "loss: 2.255414  [ 6300/60000]\n",
      "loss: 2.272359  [ 7000/60000]\n",
      "loss: 2.281804  [ 7700/60000]\n",
      "loss: 2.244925  [ 8400/60000]\n",
      "loss: 2.246309  [ 9100/60000]\n",
      "loss: 2.283076  [ 9800/60000]\n",
      "loss: 2.198605  [10500/60000]\n",
      "loss: 2.280356  [11200/60000]\n",
      "loss: 2.229830  [11900/60000]\n",
      "loss: 2.245639  [12600/60000]\n",
      "loss: 2.223645  [13300/60000]\n",
      "loss: 2.227009  [14000/60000]\n",
      "loss: 2.268746  [14700/60000]\n",
      "loss: 2.258025  [15400/60000]\n",
      "loss: 2.224022  [16100/60000]\n",
      "loss: 2.209796  [16800/60000]\n",
      "loss: 2.240609  [17500/60000]\n",
      "loss: 2.221389  [18200/60000]\n",
      "loss: 2.203494  [18900/60000]\n",
      "loss: 2.189700  [19600/60000]\n",
      "loss: 2.174146  [20300/60000]\n",
      "loss: 2.250461  [21000/60000]\n",
      "loss: 2.257839  [21700/60000]\n",
      "loss: 2.153018  [22400/60000]\n",
      "loss: 2.111498  [23100/60000]\n",
      "loss: 2.223605  [23800/60000]\n",
      "loss: 2.251138  [24500/60000]\n",
      "loss: 2.164793  [25200/60000]\n",
      "loss: 2.192696  [25900/60000]\n",
      "loss: 2.211448  [26600/60000]\n",
      "loss: 2.075450  [27300/60000]\n",
      "loss: 2.142977  [28000/60000]\n",
      "loss: 2.232011  [28700/60000]\n",
      "loss: 1.939883  [29400/60000]\n",
      "loss: 2.167431  [30100/60000]\n",
      "loss: 2.103234  [30800/60000]\n",
      "loss: 2.124007  [31500/60000]\n",
      "loss: 2.189232  [32200/60000]\n",
      "loss: 2.190532  [32900/60000]\n",
      "loss: 2.031519  [33600/60000]\n",
      "loss: 1.951618  [34300/60000]\n",
      "loss: 1.957602  [35000/60000]\n",
      "loss: 2.142906  [35700/60000]\n",
      "loss: 2.022014  [36400/60000]\n",
      "loss: 1.931600  [37100/60000]\n",
      "loss: 2.147620  [37800/60000]\n",
      "loss: 2.099834  [38500/60000]\n",
      "loss: 1.935382  [39200/60000]\n",
      "loss: 2.043108  [39900/60000]\n",
      "loss: 1.934502  [40600/60000]\n",
      "loss: 2.084308  [41300/60000]\n",
      "loss: 2.103951  [42000/60000]\n",
      "loss: 1.938370  [42700/60000]\n",
      "loss: 2.082979  [43400/60000]\n",
      "loss: 1.895954  [44100/60000]\n",
      "loss: 1.880782  [44800/60000]\n",
      "loss: 1.959278  [45500/60000]\n",
      "loss: 1.972560  [46200/60000]\n",
      "loss: 1.706238  [46900/60000]\n",
      "loss: 1.933159  [47600/60000]\n",
      "loss: 1.990628  [48300/60000]\n",
      "loss: 2.004370  [49000/60000]\n",
      "loss: 1.763039  [49700/60000]\n",
      "loss: 1.215748  [50400/60000]\n",
      "loss: 1.755916  [51100/60000]\n",
      "loss: 1.881105  [51800/60000]\n",
      "loss: 1.423289  [52500/60000]\n",
      "loss: 1.602243  [53200/60000]\n",
      "loss: 1.490173  [53900/60000]\n",
      "loss: 1.351357  [54600/60000]\n",
      "loss: 1.567170  [55300/60000]\n",
      "loss: 1.194419  [56000/60000]\n",
      "loss: 1.352901  [56700/60000]\n",
      "loss: 1.012640  [57400/60000]\n",
      "loss: 1.320055  [58100/60000]\n",
      "loss: 1.433198  [58800/60000]\n",
      "loss: 1.080445  [59500/60000]\n",
      "Test Result: \n",
      " Accuracy: 70.2%, Avg loss: 1.132165 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.331792  [    0/60000]\n",
      "loss: 1.269112  [  700/60000]\n",
      "loss: 1.221703  [ 1400/60000]\n",
      "loss: 1.238506  [ 2100/60000]\n",
      "loss: 1.228739  [ 2800/60000]\n",
      "loss: 0.917213  [ 3500/60000]\n",
      "loss: 0.560521  [ 4200/60000]\n",
      "loss: 1.286424  [ 4900/60000]\n",
      "loss: 0.846949  [ 5600/60000]\n",
      "loss: 0.732486  [ 6300/60000]\n",
      "loss: 0.766375  [ 7000/60000]\n",
      "loss: 0.483184  [ 7700/60000]\n",
      "loss: 0.875171  [ 8400/60000]\n",
      "loss: 1.055576  [ 9100/60000]\n",
      "loss: 0.625324  [ 9800/60000]\n",
      "loss: 0.764481  [10500/60000]\n",
      "loss: 0.810021  [11200/60000]\n",
      "loss: 1.240493  [11900/60000]\n",
      "loss: 0.601639  [12600/60000]\n",
      "loss: 0.810687  [13300/60000]\n",
      "loss: 1.028636  [14000/60000]\n",
      "loss: 0.693751  [14700/60000]\n",
      "loss: 0.843437  [15400/60000]\n",
      "loss: 0.404185  [16100/60000]\n",
      "loss: 0.153877  [16800/60000]\n",
      "loss: 1.577735  [17500/60000]\n",
      "loss: 0.803860  [18200/60000]\n",
      "loss: 0.210447  [18900/60000]\n",
      "loss: 1.225469  [19600/60000]\n",
      "loss: 0.704623  [20300/60000]\n",
      "loss: 0.347961  [21000/60000]\n",
      "loss: 0.595596  [21700/60000]\n",
      "loss: 1.195122  [22400/60000]\n",
      "loss: 0.325872  [23100/60000]\n",
      "loss: 1.219759  [23800/60000]\n",
      "loss: 0.304705  [24500/60000]\n",
      "loss: 0.887902  [25200/60000]\n",
      "loss: 0.442971  [25900/60000]\n",
      "loss: 0.402590  [26600/60000]\n",
      "loss: 1.287442  [27300/60000]\n",
      "loss: 0.776018  [28000/60000]\n",
      "loss: 0.838131  [28700/60000]\n",
      "loss: 0.787751  [29400/60000]\n",
      "loss: 0.669308  [30100/60000]\n",
      "loss: 0.359152  [30800/60000]\n",
      "loss: 0.733008  [31500/60000]\n",
      "loss: 0.381872  [32200/60000]\n",
      "loss: 0.323384  [32900/60000]\n",
      "loss: 0.299904  [33600/60000]\n",
      "loss: 0.178486  [34300/60000]\n",
      "loss: 0.466665  [35000/60000]\n",
      "loss: 0.855911  [35700/60000]\n",
      "loss: 1.070410  [36400/60000]\n",
      "loss: 0.677506  [37100/60000]\n",
      "loss: 0.826282  [37800/60000]\n",
      "loss: 0.673783  [38500/60000]\n",
      "loss: 0.475895  [39200/60000]\n",
      "loss: 0.337644  [39900/60000]\n",
      "loss: 0.255273  [40600/60000]\n",
      "loss: 1.072295  [41300/60000]\n",
      "loss: 0.407875  [42000/60000]\n",
      "loss: 0.716482  [42700/60000]\n",
      "loss: 0.521426  [43400/60000]\n",
      "loss: 0.540994  [44100/60000]\n",
      "loss: 0.808876  [44800/60000]\n",
      "loss: 0.858031  [45500/60000]\n",
      "loss: 0.846958  [46200/60000]\n",
      "loss: 0.933900  [46900/60000]\n",
      "loss: 0.387769  [47600/60000]\n",
      "loss: 0.527243  [48300/60000]\n",
      "loss: 0.226626  [49000/60000]\n",
      "loss: 0.227769  [49700/60000]\n",
      "loss: 0.528990  [50400/60000]\n",
      "loss: 0.638492  [51100/60000]\n",
      "loss: 0.281550  [51800/60000]\n",
      "loss: 0.427626  [52500/60000]\n",
      "loss: 0.654277  [53200/60000]\n",
      "loss: 0.164858  [53900/60000]\n",
      "loss: 0.461132  [54600/60000]\n",
      "loss: 0.474596  [55300/60000]\n",
      "loss: 1.165812  [56000/60000]\n",
      "loss: 0.941460  [56700/60000]\n",
      "loss: 0.947759  [57400/60000]\n",
      "loss: 0.960695  [58100/60000]\n",
      "loss: 0.504724  [58800/60000]\n",
      "loss: 0.289306  [59500/60000]\n",
      "Test Result: \n",
      " Accuracy: 83.9%, Avg loss: 0.545329 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.385707  [    0/60000]\n",
      "loss: 0.932673  [  700/60000]\n",
      "loss: 0.434332  [ 1400/60000]\n",
      "loss: 0.491781  [ 2100/60000]\n",
      "loss: 0.224014  [ 2800/60000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.592299  [ 3500/60000]\n",
      "loss: 0.343283  [ 4200/60000]\n",
      "loss: 0.491534  [ 4900/60000]\n",
      "loss: 0.169804  [ 5600/60000]\n",
      "loss: 0.532944  [ 6300/60000]\n",
      "loss: 0.802433  [ 7000/60000]\n",
      "loss: 0.394602  [ 7700/60000]\n",
      "loss: 0.466166  [ 8400/60000]\n",
      "loss: 0.158763  [ 9100/60000]\n",
      "loss: 0.668184  [ 9800/60000]\n",
      "loss: 0.758083  [10500/60000]\n",
      "loss: 0.925226  [11200/60000]\n",
      "loss: 0.411907  [11900/60000]\n",
      "loss: 0.404014  [12600/60000]\n",
      "loss: 0.164542  [13300/60000]\n",
      "loss: 0.488603  [14000/60000]\n",
      "loss: 0.638701  [14700/60000]\n",
      "loss: 0.257769  [15400/60000]\n",
      "loss: 0.221159  [16100/60000]\n",
      "loss: 0.588521  [16800/60000]\n",
      "loss: 0.209653  [17500/60000]\n",
      "loss: 0.360118  [18200/60000]\n",
      "loss: 0.123242  [18900/60000]\n",
      "loss: 0.330729  [19600/60000]\n",
      "loss: 0.484041  [20300/60000]\n",
      "loss: 0.934689  [21000/60000]\n",
      "loss: 0.528754  [21700/60000]\n",
      "loss: 0.810643  [22400/60000]\n",
      "loss: 0.226418  [23100/60000]\n",
      "loss: 0.339514  [23800/60000]\n",
      "loss: 0.930502  [24500/60000]\n",
      "loss: 0.636407  [25200/60000]\n",
      "loss: 0.758432  [25900/60000]\n",
      "loss: 0.197400  [26600/60000]\n",
      "loss: 0.044470  [27300/60000]\n",
      "loss: 0.280796  [28000/60000]\n",
      "loss: 0.161671  [28700/60000]\n",
      "loss: 0.304300  [29400/60000]\n",
      "loss: 0.191903  [30100/60000]\n",
      "loss: 0.171065  [30800/60000]\n",
      "loss: 0.352606  [31500/60000]\n",
      "loss: 0.713425  [32200/60000]\n",
      "loss: 0.995459  [32900/60000]\n",
      "loss: 0.722980  [33600/60000]\n",
      "loss: 0.216372  [34300/60000]\n",
      "loss: 1.624365  [35000/60000]\n",
      "loss: 0.462736  [35700/60000]\n",
      "loss: 0.622559  [36400/60000]\n",
      "loss: 0.499575  [37100/60000]\n",
      "loss: 0.339810  [37800/60000]\n",
      "loss: 0.156357  [38500/60000]\n",
      "loss: 0.100879  [39200/60000]\n",
      "loss: 0.763488  [39900/60000]\n",
      "loss: 0.081074  [40600/60000]\n",
      "loss: 0.512005  [41300/60000]\n",
      "loss: 0.040514  [42000/60000]\n",
      "loss: 0.851329  [42700/60000]\n",
      "loss: 0.136084  [43400/60000]\n",
      "loss: 0.208298  [44100/60000]\n",
      "loss: 0.254507  [44800/60000]\n",
      "loss: 0.279649  [45500/60000]\n",
      "loss: 0.560248  [46200/60000]\n",
      "loss: 0.126405  [46900/60000]\n",
      "loss: 0.128471  [47600/60000]\n",
      "loss: 0.854932  [48300/60000]\n",
      "loss: 0.231423  [49000/60000]\n",
      "loss: 0.097393  [49700/60000]\n",
      "loss: 0.399402  [50400/60000]\n",
      "loss: 0.543935  [51100/60000]\n",
      "loss: 0.648271  [51800/60000]\n",
      "loss: 0.799050  [52500/60000]\n",
      "loss: 0.168116  [53200/60000]\n",
      "loss: 0.035552  [53900/60000]\n",
      "loss: 0.419200  [54600/60000]\n",
      "loss: 0.082982  [55300/60000]\n",
      "loss: 0.063969  [56000/60000]\n",
      "loss: 0.213705  [56700/60000]\n",
      "loss: 0.241429  [57400/60000]\n",
      "loss: 0.357198  [58100/60000]\n",
      "loss: 0.439837  [58800/60000]\n",
      "loss: 0.213102  [59500/60000]\n",
      "Test Result: \n",
      " Accuracy: 88.4%, Avg loss: 0.398630 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.403261  [    0/60000]\n",
      "loss: 0.251404  [  700/60000]\n",
      "loss: 0.278112  [ 1400/60000]\n",
      "loss: 0.090823  [ 2100/60000]\n",
      "loss: 0.120052  [ 2800/60000]\n",
      "loss: 0.099074  [ 3500/60000]\n",
      "loss: 0.377934  [ 4200/60000]\n",
      "loss: 0.183800  [ 4900/60000]\n",
      "loss: 0.115703  [ 5600/60000]\n",
      "loss: 0.486209  [ 6300/60000]\n",
      "loss: 0.397573  [ 7000/60000]\n",
      "loss: 0.047337  [ 7700/60000]\n",
      "loss: 0.314310  [ 8400/60000]\n",
      "loss: 0.088008  [ 9100/60000]\n",
      "loss: 0.319202  [ 9800/60000]\n",
      "loss: 0.468568  [10500/60000]\n",
      "loss: 0.211002  [11200/60000]\n",
      "loss: 0.620006  [11900/60000]\n",
      "loss: 0.296477  [12600/60000]\n",
      "loss: 0.199881  [13300/60000]\n",
      "loss: 0.662896  [14000/60000]\n",
      "loss: 1.365112  [14700/60000]\n",
      "loss: 0.651539  [15400/60000]\n",
      "loss: 0.380860  [16100/60000]\n",
      "loss: 0.238514  [16800/60000]\n",
      "loss: 1.315005  [17500/60000]\n",
      "loss: 0.835579  [18200/60000]\n",
      "loss: 0.197842  [18900/60000]\n",
      "loss: 1.407652  [19600/60000]\n",
      "loss: 0.119323  [20300/60000]\n",
      "loss: 0.074239  [21000/60000]\n",
      "loss: 0.679907  [21700/60000]\n",
      "loss: 0.220638  [22400/60000]\n",
      "loss: 0.224260  [23100/60000]\n",
      "loss: 0.357943  [23800/60000]\n",
      "loss: 0.941080  [24500/60000]\n",
      "loss: 0.190063  [25200/60000]\n",
      "loss: 0.392445  [25900/60000]\n",
      "loss: 0.886516  [26600/60000]\n",
      "loss: 0.556389  [27300/60000]\n",
      "loss: 0.560836  [28000/60000]\n",
      "loss: 0.680268  [28700/60000]\n",
      "loss: 0.195247  [29400/60000]\n",
      "loss: 0.399805  [30100/60000]\n",
      "loss: 0.404491  [30800/60000]\n",
      "loss: 0.043493  [31500/60000]\n",
      "loss: 0.098166  [32200/60000]\n",
      "loss: 0.969940  [32900/60000]\n",
      "loss: 0.043682  [33600/60000]\n",
      "loss: 0.283683  [34300/60000]\n",
      "loss: 0.055301  [35000/60000]\n",
      "loss: 0.159601  [35700/60000]\n",
      "loss: 0.457299  [36400/60000]\n",
      "loss: 0.841394  [37100/60000]\n",
      "loss: 0.693476  [37800/60000]\n",
      "loss: 0.056239  [38500/60000]\n",
      "loss: 0.248470  [39200/60000]\n",
      "loss: 0.239849  [39900/60000]\n",
      "loss: 0.794770  [40600/60000]\n",
      "loss: 0.109719  [41300/60000]\n",
      "loss: 0.060475  [42000/60000]\n",
      "loss: 0.123273  [42700/60000]\n",
      "loss: 0.397674  [43400/60000]\n",
      "loss: 0.146525  [44100/60000]\n",
      "loss: 0.139246  [44800/60000]\n",
      "loss: 0.524661  [45500/60000]\n",
      "loss: 0.331461  [46200/60000]\n",
      "loss: 0.332928  [46900/60000]\n",
      "loss: 0.252153  [47600/60000]\n",
      "loss: 0.253767  [48300/60000]\n",
      "loss: 0.296795  [49000/60000]\n",
      "loss: 1.307182  [49700/60000]\n",
      "loss: 1.486323  [50400/60000]\n",
      "loss: 0.053359  [51100/60000]\n",
      "loss: 0.592447  [51800/60000]\n",
      "loss: 0.066930  [52500/60000]\n",
      "loss: 0.588110  [53200/60000]\n",
      "loss: 1.104906  [53900/60000]\n",
      "loss: 0.245463  [54600/60000]\n",
      "loss: 2.105090  [55300/60000]\n",
      "loss: 0.532565  [56000/60000]\n",
      "loss: 0.211756  [56700/60000]\n",
      "loss: 0.050466  [57400/60000]\n",
      "loss: 0.150193  [58100/60000]\n",
      "loss: 0.195330  [58800/60000]\n",
      "loss: 0.204581  [59500/60000]\n",
      "Test Result: \n",
      " Accuracy: 90.5%, Avg loss: 0.327294 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.617647  [    0/60000]\n",
      "loss: 0.724803  [  700/60000]\n",
      "loss: 0.360438  [ 1400/60000]\n",
      "loss: 0.118348  [ 2100/60000]\n",
      "loss: 0.186096  [ 2800/60000]\n",
      "loss: 0.575253  [ 3500/60000]\n",
      "loss: 0.583126  [ 4200/60000]\n",
      "loss: 0.146098  [ 4900/60000]\n",
      "loss: 0.088527  [ 5600/60000]\n",
      "loss: 0.101035  [ 6300/60000]\n",
      "loss: 0.396834  [ 7000/60000]\n",
      "loss: 0.418642  [ 7700/60000]\n",
      "loss: 0.527834  [ 8400/60000]\n",
      "loss: 0.632113  [ 9100/60000]\n",
      "loss: 0.121590  [ 9800/60000]\n",
      "loss: 0.044351  [10500/60000]\n",
      "loss: 0.276141  [11200/60000]\n",
      "loss: 0.095110  [11900/60000]\n",
      "loss: 0.076265  [12600/60000]\n",
      "loss: 0.122412  [13300/60000]\n",
      "loss: 0.052171  [14000/60000]\n",
      "loss: 0.238185  [14700/60000]\n",
      "loss: 0.285835  [15400/60000]\n",
      "loss: 0.309463  [16100/60000]\n",
      "loss: 0.506615  [16800/60000]\n",
      "loss: 0.533526  [17500/60000]\n",
      "loss: 0.078511  [18200/60000]\n",
      "loss: 0.134758  [18900/60000]\n",
      "loss: 0.587389  [19600/60000]\n",
      "loss: 0.093639  [20300/60000]\n",
      "loss: 0.130134  [21000/60000]\n",
      "loss: 0.251189  [21700/60000]\n",
      "loss: 0.310595  [22400/60000]\n",
      "loss: 0.324120  [23100/60000]\n",
      "loss: 0.149139  [23800/60000]\n",
      "loss: 0.121586  [24500/60000]\n",
      "loss: 0.130828  [25200/60000]\n",
      "loss: 0.017293  [25900/60000]\n",
      "loss: 0.075468  [26600/60000]\n",
      "loss: 0.175970  [27300/60000]\n",
      "loss: 0.228442  [28000/60000]\n",
      "loss: 0.056019  [28700/60000]\n",
      "loss: 0.505615  [29400/60000]\n",
      "loss: 0.171614  [30100/60000]\n",
      "loss: 0.026440  [30800/60000]\n",
      "loss: 0.611965  [31500/60000]\n",
      "loss: 0.592398  [32200/60000]\n",
      "loss: 0.034980  [32900/60000]\n",
      "loss: 0.019591  [33600/60000]\n",
      "loss: 0.895320  [34300/60000]\n",
      "loss: 0.331879  [35000/60000]\n",
      "loss: 0.147295  [35700/60000]\n",
      "loss: 0.030166  [36400/60000]\n",
      "loss: 0.584853  [37100/60000]\n",
      "loss: 0.208348  [37800/60000]\n",
      "loss: 0.523912  [38500/60000]\n",
      "loss: 0.329895  [39200/60000]\n",
      "loss: 0.268345  [39900/60000]\n",
      "loss: 0.675659  [40600/60000]\n",
      "loss: 0.713198  [41300/60000]\n",
      "loss: 0.310188  [42000/60000]\n",
      "loss: 0.263304  [42700/60000]\n",
      "loss: 0.617008  [43400/60000]\n",
      "loss: 0.103008  [44100/60000]\n",
      "loss: 0.240579  [44800/60000]\n",
      "loss: 0.110082  [45500/60000]\n",
      "loss: 0.574490  [46200/60000]\n",
      "loss: 0.395696  [46900/60000]\n",
      "loss: 0.604145  [47600/60000]\n",
      "loss: 1.233694  [48300/60000]\n",
      "loss: 0.021836  [49000/60000]\n",
      "loss: 0.148448  [49700/60000]\n",
      "loss: 0.553903  [50400/60000]\n",
      "loss: 0.123989  [51100/60000]\n",
      "loss: 0.034481  [51800/60000]\n",
      "loss: 0.711044  [52500/60000]\n",
      "loss: 0.035964  [53200/60000]\n",
      "loss: 0.755534  [53900/60000]\n",
      "loss: 0.529578  [54600/60000]\n",
      "loss: 0.356766  [55300/60000]\n",
      "loss: 0.338281  [56000/60000]\n",
      "loss: 0.769984  [56700/60000]\n",
      "loss: 0.730272  [57400/60000]\n",
      "loss: 0.170126  [58100/60000]\n",
      "loss: 0.130765  [58800/60000]\n",
      "loss: 0.075147  [59500/60000]\n",
      "Test Result: \n",
      " Accuracy: 91.7%, Avg loss: 0.285480 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.490626  [    0/60000]\n",
      "loss: 0.034499  [  700/60000]\n",
      "loss: 0.957506  [ 1400/60000]\n",
      "loss: 0.022424  [ 2100/60000]\n",
      "loss: 1.852773  [ 2800/60000]\n",
      "loss: 0.034386  [ 3500/60000]\n",
      "loss: 0.687980  [ 4200/60000]\n",
      "loss: 0.125498  [ 4900/60000]\n",
      "loss: 0.025503  [ 5600/60000]\n",
      "loss: 0.195059  [ 6300/60000]\n",
      "loss: 0.150094  [ 7000/60000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.069253  [ 7700/60000]\n",
      "loss: 0.073238  [ 8400/60000]\n",
      "loss: 0.016108  [ 9100/60000]\n",
      "loss: 0.113333  [ 9800/60000]\n",
      "loss: 0.140151  [10500/60000]\n",
      "loss: 0.081246  [11200/60000]\n",
      "loss: 0.445822  [11900/60000]\n",
      "loss: 0.047745  [12600/60000]\n",
      "loss: 0.101825  [13300/60000]\n",
      "loss: 0.346911  [14000/60000]\n",
      "loss: 0.421891  [14700/60000]\n",
      "loss: 0.056709  [15400/60000]\n",
      "loss: 0.197385  [16100/60000]\n",
      "loss: 1.278250  [16800/60000]\n",
      "loss: 0.474088  [17500/60000]\n",
      "loss: 0.147612  [18200/60000]\n",
      "loss: 0.664717  [18900/60000]\n",
      "loss: 0.155857  [19600/60000]\n",
      "loss: 0.418506  [20300/60000]\n",
      "loss: 0.311827  [21000/60000]\n",
      "loss: 0.013325  [21700/60000]\n",
      "loss: 0.737899  [22400/60000]\n",
      "loss: 0.597706  [23100/60000]\n",
      "loss: 0.101762  [23800/60000]\n",
      "loss: 0.672306  [24500/60000]\n",
      "loss: 0.860433  [25200/60000]\n",
      "loss: 0.232525  [25900/60000]\n",
      "loss: 0.079299  [26600/60000]\n",
      "loss: 0.136288  [27300/60000]\n",
      "loss: 0.835304  [28000/60000]\n",
      "loss: 1.125659  [28700/60000]\n",
      "loss: 0.120848  [29400/60000]\n",
      "loss: 0.103311  [30100/60000]\n",
      "loss: 0.136710  [30800/60000]\n",
      "loss: 0.058618  [31500/60000]\n",
      "loss: 0.176389  [32200/60000]\n",
      "loss: 0.225865  [32900/60000]\n",
      "loss: 0.205154  [33600/60000]\n",
      "loss: 0.819942  [34300/60000]\n",
      "loss: 0.805297  [35000/60000]\n",
      "loss: 0.198429  [35700/60000]\n",
      "loss: 0.765119  [36400/60000]\n",
      "loss: 0.130786  [37100/60000]\n",
      "loss: 0.016664  [37800/60000]\n",
      "loss: 0.131577  [38500/60000]\n",
      "loss: 0.064242  [39200/60000]\n",
      "loss: 0.153283  [39900/60000]\n",
      "loss: 0.181924  [40600/60000]\n",
      "loss: 0.111904  [41300/60000]\n",
      "loss: 0.073485  [42000/60000]\n",
      "loss: 0.133131  [42700/60000]\n",
      "loss: 0.199806  [43400/60000]\n",
      "loss: 0.503472  [44100/60000]\n",
      "loss: 0.606160  [44800/60000]\n",
      "loss: 0.375239  [45500/60000]\n",
      "loss: 0.339286  [46200/60000]\n",
      "loss: 0.608548  [46900/60000]\n",
      "loss: 0.523917  [47600/60000]\n",
      "loss: 0.013072  [48300/60000]\n",
      "loss: 0.288936  [49000/60000]\n",
      "loss: 0.054854  [49700/60000]\n",
      "loss: 0.026796  [50400/60000]\n",
      "loss: 0.413706  [51100/60000]\n",
      "loss: 0.053463  [51800/60000]\n",
      "loss: 0.059467  [52500/60000]\n",
      "loss: 0.034337  [53200/60000]\n",
      "loss: 0.505527  [53900/60000]\n",
      "loss: 0.453391  [54600/60000]\n",
      "loss: 0.289517  [55300/60000]\n",
      "loss: 0.051196  [56000/60000]\n",
      "loss: 0.787299  [56700/60000]\n",
      "loss: 0.266595  [57400/60000]\n",
      "loss: 0.178340  [58100/60000]\n",
      "loss: 0.272760  [58800/60000]\n",
      "loss: 0.473231  [59500/60000]\n",
      "Test Result: \n",
      " Accuracy: 92.7%, Avg loss: 0.248410 \n",
      "\n",
      "Training is done!\n"
     ]
    }
   ],
   "source": [
    "# Traing phase\n",
    "\n",
    "epochs = 7\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataset, model, loss_fn, optimizer)\n",
    "    test(test_dataset, model, loss_fn)\n",
    "print(\"Training is done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc7d7da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8cc1d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruning function decleration\n",
    "\n",
    "def pruning(model, prune_method, rank_method, amount):\n",
    "    weights = model.state_dict()\n",
    "    layers = list(weights)\n",
    "    rank_dict = {}\n",
    "    pruned_weights = []\n",
    "    for layer in layers[:-1]:\n",
    "        layer_weight_data = weights[layer]\n",
    "        weight_matrix = np.array(weights[layer])\n",
    "        if prune_method == 'weight':\n",
    "            rank_dict[layer]=(rankdata(np.abs(weight_matrix), method=rank_method) - 1).reshape(weight_matrix.shape)\n",
    "        elif prune_method == 'unit':\n",
    "            norm = linalg.norm(weight_matrix, axis=0)\n",
    "            norm = np.tile(norm, (weight_matrix.shape[0],1))\n",
    "            rank_dict[layer] = (rankdata(norm, method=rank_method) - 1).reshape(norm.shape)                                                                             \n",
    "        rank_below_x_percent = np.ceil(np.max(rank_dict[layer]) * amount)\n",
    "        rank_dict[layer][rank_dict[layer] <= rank_below_x_percent] = 0\n",
    "        rank_dict[layer][rank_dict[layer] > rank_below_x_percent] = 1\n",
    "        weight_matrix = weight_matrix * rank_dict[layer]\n",
    "        layer_weight_data[...] = torch.from_numpy(weight_matrix)\n",
    "        pruned_weights.append(layer_weight_data)\n",
    "    pruned_weights.append(weights[layers[-1]])\n",
    "    new_model_state_dict = OrderedDict()\n",
    "    for layer, pruned_weight in zip(layers, pruned_weights):\n",
    "        new_model_state_dict[layer] = pruned_weight\n",
    "    model.state_dict = new_model_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1d33b403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result: \n",
      " Accuracy: 92.7%, Avg loss: 0.248410 \n",
      "\n",
      "Test Result: \n",
      " Accuracy: 92.8%, Avg loss: 0.249589 \n",
      "\n",
      "Test Result: \n",
      " Accuracy: 91.0%, Avg loss: 0.302966 \n",
      "\n",
      "Test Result: \n",
      " Accuracy: 89.5%, Avg loss: 0.368959 \n",
      "\n",
      "Test Result: \n",
      " Accuracy: 88.5%, Avg loss: 0.462941 \n",
      "\n",
      "Test Result: \n",
      " Accuracy: 86.0%, Avg loss: 0.698541 \n",
      "\n",
      "Test Result: \n",
      " Accuracy: 78.5%, Avg loss: 1.277890 \n",
      "\n",
      "Test Result: \n",
      " Accuracy: 75.1%, Avg loss: 1.729068 \n",
      "\n",
      "Test Result: \n",
      " Accuracy: 65.9%, Avg loss: 1.973941 \n",
      "\n",
      "Test Result: \n",
      " Accuracy: 52.2%, Avg loss: 2.252571 \n",
      "\n",
      "Test Result: \n",
      " Accuracy: 92.7%, Avg loss: 0.248410 \n",
      "\n",
      "Test Result: \n",
      " Accuracy: 92.1%, Avg loss: 0.283961 \n",
      "\n",
      "Test Result: \n",
      " Accuracy: 89.2%, Avg loss: 0.499449 \n",
      "\n",
      "Test Result: \n",
      " Accuracy: 85.1%, Avg loss: 0.783401 \n",
      "\n",
      "Test Result: \n",
      " Accuracy: 75.3%, Avg loss: 1.259721 \n",
      "\n",
      "Test Result: \n",
      " Accuracy: 58.3%, Avg loss: 1.856287 \n",
      "\n",
      "Test Result: \n",
      " Accuracy: 23.8%, Avg loss: 2.242048 \n",
      "\n",
      "Test Result: \n",
      " Accuracy: 21.6%, Avg loss: 2.297726 \n",
      "\n",
      "Test Result: \n",
      " Accuracy: 10.5%, Avg loss: 2.301531 \n",
      "\n",
      "Test Result: \n",
      " Accuracy: 6.0%, Avg loss: 2.302569 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pruning phase\n",
    "\n",
    "prune_percentage_data = [.0, .25, .50, .60, .70, .80, .90, .95, .97, .99]\n",
    "weight_pruning_accuracy_data = []\n",
    "unit_pruning_accuracy_data = []\n",
    "\n",
    "# Weight pruning phase\n",
    "\n",
    "for percentage_data in prune_percentage_data[0:]:   \n",
    "    model = NeuralNet()\n",
    "    model.load_state_dict(torch.load(\"model.pth\"))\n",
    "    pruning(model, 'weight', 'ordinal', percentage_data)\n",
    "    weight_pruning_accuracy_data.append(test(test_dataset, model, loss_fn))\n",
    "\n",
    "# Unit pruning phase\n",
    "\n",
    "for percentage_data in prune_percentage_data[0:]:\n",
    "    model = NeuralNet()\n",
    "    model.load_state_dict(torch.load(\"model.pth\"))\n",
    "    pruning(model, 'unit', 'ordinal', percentage_data)    \n",
    "    unit_pruning_accuracy_data.append(test(test_dataset, model, loss_fn)) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "62a844c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the sparsity vs accuracy graph using matplotlib\n",
    "\n",
    "plt.plot(prune_percentage_data, weight_pruning_accuracy_data, label='Weight Pruning')\n",
    "plt.plot(prune_percentage_data, unit_pruning_accuracy_data, label='Unit Pruning')\n",
    "\n",
    "plt.legend(loc='lower left')\n",
    "plt.xlabel('Percentage sparsity')\n",
    "plt.ylabel('Percentage accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f99a8212",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame({'prune percentage':prune_percentage_data, 'weight pruning':weight_pruning_accuracy_data, 'unit pruning':unit_pruning_accuracy_data})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a93c4fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prune percentage</th>\n",
       "      <th>weight pruning</th>\n",
       "      <th>unit pruning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9268</td>\n",
       "      <td>0.9268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.9276</td>\n",
       "      <td>0.9206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.9105</td>\n",
       "      <td>0.8918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.8953</td>\n",
       "      <td>0.8507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.8855</td>\n",
       "      <td>0.7527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.8603</td>\n",
       "      <td>0.5830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.7849</td>\n",
       "      <td>0.2375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.7514</td>\n",
       "      <td>0.2162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.6586</td>\n",
       "      <td>0.1052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.5216</td>\n",
       "      <td>0.0604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prune percentage  weight pruning  unit pruning\n",
       "0              0.00          0.9268        0.9268\n",
       "1              0.25          0.9276        0.9206\n",
       "2              0.50          0.9105        0.8918\n",
       "3              0.60          0.8953        0.8507\n",
       "4              0.70          0.8855        0.7527\n",
       "5              0.80          0.8603        0.5830\n",
       "6              0.90          0.7849        0.2375\n",
       "7              0.95          0.7514        0.2162\n",
       "8              0.97          0.6586        0.1052\n",
       "9              0.99          0.5216        0.0604"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abbe39d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
